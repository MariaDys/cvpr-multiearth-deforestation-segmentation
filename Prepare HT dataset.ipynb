{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deforestation Dataset\n",
    "\n",
    "This notebook prepares the deforestation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import random\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from multiearth_challenge.datasets import segmentation_dataset as sd\n",
    "\n",
    "from multiearth_challenge.datasets import base_datasets as bd\n",
    "\n",
    "from multiearth_challenge import tiff_file_tools as tft\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/multiearth2023-dataset-final/'\n",
    "DP_PATH = './dp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_target = pd.read_csv('forest_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_target.date.min()\n",
    "forest_target.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_target.shape\n",
    "forest_target.head()\n",
    "forest_target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metas = [\n",
    "    'sat_ls8_landsat8_train_meta.csv',\n",
    "    'sat_s2_sent2_b5-b8_train_meta.csv',\n",
    "    'sat_s1_sent1_train_meta.csv',\n",
    "    'sat_s2_sent2_b9-b12_train_meta.csv',\n",
    "    'sat_s2_sent2_b1-b4_train_meta.csv',\n",
    "]\n",
    "tile_stats = pd.concat([pd.read_csv(f\"./dp/{f}\") for f in metas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    tile_stats.groupby(['source', 'band']).imin.min(),\n",
    "    tile_stats.groupby(['source', 'band']).imean.mean(),\n",
    "    tile_stats.groupby(['source', 'band']).imax.max(),\n",
    "], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_coords = tile_stats.groupby(['source', 'lat', 'lon', 'source_date']).band.count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# candidates for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = forest_target.merge(source_coords, on=['lat', 'lon'], suffixes = ['_target', '_source'])\n",
    "\n",
    "candidates = candidates[candidates.date > candidates.source_date] # sat images from the past\n",
    "candidates = candidates.sort_values(by=['lat', 'lon', 'date', 'source', 'source_date'])\n",
    "candidates['source_rank'] =  candidates.groupby(['lat', 'lon', 'date', 'source']).source_date.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.shape\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = candidates[candidates.source_rank <= 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest.groupby(['source', 'source_rank']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_LIMITS = {\n",
    "    \"ls8\": {\n",
    "#         \"SR_B1\": (5000, 45000),\n",
    "        \"SR_B2\": (5000, 45000),\n",
    "        \"SR_B3\": (5000, 45000),\n",
    "        \"SR_B4\": (5000, 45000), \n",
    "        \"SR_B5\": (5000, 45000),\n",
    "        \"SR_B6\": (5000, 45000),\n",
    "        \"SR_B7\": (5000, 45000),\n",
    "#         \"ST_B10\": (5000, 45000),\n",
    "    },\n",
    "    \"s1\": {\n",
    "        \"VH\": (-30, 2),\n",
    "        \"VV\": (-20, 2),\n",
    "    },\n",
    "    \"s2\": {\n",
    "#         \"B1\": (1000, 10000),\n",
    "        \"B2\": (1000, 10000),\n",
    "        \"B3\": (1000, 10000),\n",
    "        \"B4\": (1000, 10000),\n",
    "        \"B5\": (1000, 10000),\n",
    "        \"B6\": (1000, 10000),\n",
    "        \"B7\": (1000, 10000),\n",
    "        \"B8\": (1000, 10000),\n",
    "#         \"B8A\": (1000, 10000),\n",
    "#         \"B9\": (1000, 10000),\n",
    "        \"B11\": (1000, 10000),\n",
    "        \"B12\": (1000, 10000),\n",
    "    },\n",
    "}\n",
    "\n",
    "def normalize(img):\n",
    "    img = img.astype(np.float64)\n",
    "    img -= np.mean(img)\n",
    "    img_std = np.std(img)\n",
    "    img += img_std\n",
    "    img /= img_std * 3.0\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "def get_sat_img(source, band, lat, lon, source_date, use_mean_std=False):\n",
    "    DP_PATH = './dp'\n",
    "    SOURCE_DIR = f\"{DP_PATH}/{source}\"\n",
    "    source_year = source_date[:4]\n",
    "    source_key = f\"{source}_{band}_{round(lat, 2)}_{round(lon, 2)}_{source_date}\"\n",
    "    source_path = f\"{SOURCE_DIR}/{band}/{source_year}/{source_key}.npy\"\n",
    "    \n",
    "    x = np.load(source_path)\n",
    "    if use_mean_std:\n",
    "        x = normalize(x)\n",
    "    else:\n",
    "        band_min, band_max = BAND_LIMITS[source][band]\n",
    "        x = x.clip(band_min, band_max)\n",
    "        \n",
    "        if x.max() > x.min():\n",
    "            x = (x - x.min()) / (x.max() - x.min())\n",
    "        else:\n",
    "            x = np.zeros((256, 256))\n",
    "    x = cv2.resize(x, dsize=(256, 256))\n",
    "    x = x * 255\n",
    "    return x.astype(np.uint8)\n",
    "\n",
    "def get_input_tensor(df):\n",
    "    chs = []\n",
    "    for source in ['ls8', 's1', 's2']:\n",
    "        for source_rank in [1, 2, 3]:\n",
    "            row = df[(df.source == source) & (df.source_rank == source_rank)]\n",
    "            for band in BAND_LIMITS[source].keys():\n",
    "                if len(row) == 0:\n",
    "                    ch = np.zeros((256, 256))\n",
    "                else:\n",
    "                    ch = get_sat_img(source, band, row.lat.values[0], row.lon.values[0], row.source_date.values[0])\n",
    "                chs.append(ch)\n",
    "    x = np.stack(chs)\n",
    "    x = x.transpose(1, 2, 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_NAME = 'ds0'\n",
    "ROOT_DIR = '/home/gabor/h2o/multi-earth-2023'\n",
    "DS_DIR = f'{ROOT_DIR}/dp/{DS_NAME}'\n",
    "\n",
    "os.makedirs(DS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for target_path, df in tqdm(latest.groupby('target_path')):\n",
    "    x = get_input_tensor(df)\n",
    "    \n",
    "    lat = df.lat.values[0]\n",
    "    lon = df.lon.values[0]\n",
    "    target_date = df.date.values[0]\n",
    "    target_path = df.target_path.values[0]\n",
    "    \n",
    "    input_path = f\"{DS_DIR}/sats_{round(lat, 2)}_{round(lon, 2)}_{target_date}.npy\"\n",
    "    np.save(input_path, x)\n",
    "    rows.append([lat, lon, target_date, target_path, input_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(rows, columns=['lat', 'lon', 'target_date', 'target_path', 'input_path'])\n",
    "\n",
    "train_df = train_df.merge(forest_target[['target_path', 'rle', 'img_mean']], on='target_path')\n",
    "train_df.rle = train_df.rle.fillna(\"\")\n",
    "train_df['class_id'] = [['deforestation'] for  rle in train_df.rle.values]\n",
    "train_df['rles'] = [[rle] for rle in train_df.rle.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlons = train_df[['lat', 'lon']].drop_duplicates()\n",
    "latlons['rand_cv'] = 1 * (np.random.random(len(latlons)) > 0.8)\n",
    "latlons\n",
    "latlons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(latlons, on=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('rand_cv').img_mean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip deforest_v0.zip deforest_train_v0.pq deforest_valid_v0.pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.rand_cv == 0].to_parquet('deforest_train_v0.pq', engine='pyarrow', index=False)\n",
    "train_df[train_df.rand_cv == 1].to_parquet('deforest_valid_v0.pq', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
